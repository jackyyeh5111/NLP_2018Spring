{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_relation(s): \n",
    "    # 19 relations\n",
    "    relation_class = -1\n",
    "    if s == \"Cause-Effect(e1,e2)\":\n",
    "        relation_class = 0\n",
    "    elif s == \"Cause-Effect(e2,e1)\":\n",
    "        relation_class = 1\n",
    "    elif s == \"Instrument-Agency(e1,e2)\":\n",
    "        relation_class = 2\n",
    "    elif s == \"Instrument-Agency(e2,e1)\":\n",
    "        relation_class = 3\n",
    "    elif s == \"Product-Producer(e1,e2)\":\n",
    "        relation_class = 4\n",
    "    elif s == \"Product-Producer(e2,e1)\":\n",
    "        relation_class = 5\n",
    "    elif s == \"Content-Container(e1,e2)\":\n",
    "        relation_class = 6\n",
    "    elif s == \"Content-Container(e2,e1)\":\n",
    "        relation_class = 7\n",
    "    elif s == \"Entity-Origin(e1,e2)\":\n",
    "        relation_class = 8\n",
    "    elif s == \"Entity-Origin(e2,e1)\":\n",
    "        relation_class = 9\n",
    "    elif s == \"Entity-Destination(e1,e2)\":\n",
    "        relation_class = 10\n",
    "    elif s == \"Entity-Destination(e2,e1)\":\n",
    "        relation_class = 11\n",
    "    elif s == \"Component-Whole(e1,e2)\":\n",
    "        relation_class = 12\n",
    "    elif s == \"Component-Whole(e2,e1)\":\n",
    "        relation_class = 13\n",
    "    elif s == \"Member-Collection(e1,e2)\":\n",
    "        relation_class = 14\n",
    "    elif s == \"Member-Collection(e2,e1)\":\n",
    "        relation_class = 15\n",
    "    elif s == \"Message-Topic(e1,e2)\":\n",
    "        relation_class = 16\n",
    "    elif s == \"Message-Topic(e2,e1)\":\n",
    "        relation_class = 17\n",
    "    elif s == \"Other\":\n",
    "        relation_class = 18\n",
    "    \n",
    "    return relation_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(line):\n",
    "    line = line.lower()\n",
    "    e1 = re.findall(r\"<e1.*/e1>\", line)[0]\n",
    "    e2 = re.findall(r\"<e2.*/e2>\", line)[0]\n",
    "    content = re.findall(r\"<e1.*/e2>\", line)[0]\n",
    "\n",
    "    content = re.sub(u\"<e1>|</e1>|<e2>|</e2>\", \"\", content)\n",
    "    content = re.sub(u\"\\d+\", \" <num> \", content)\n",
    "\n",
    "    e1 = re.sub(r\"^<e1>|</e1>$\", \"\", e1)\n",
    "    e2 = re.sub(r\"^<e2>|</e2>$\", \"\", e2)\n",
    "    \n",
    "    return e1, e2, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_PATH = \"./data/TRAIN_FILE.txt\"\n",
    "    \n",
    "train_entities = []\n",
    "train_contents = []\n",
    "comments = []\n",
    "ys = []\n",
    "\n",
    "_class = {}\n",
    "\n",
    "\n",
    "with open(TRAIN_PATH, 'r') as f:\n",
    "    n = 0\n",
    "    for n_line, line in enumerate(f.readlines()):\n",
    "\n",
    "        if n_line % 4 == 0:\n",
    "\n",
    "            empty_content = False\n",
    "\n",
    "            e1, e2, content = clean_text(line)\n",
    "            \n",
    "            if content == '':\n",
    "                empty_content = True\n",
    "\n",
    "            if empty_content == False:\n",
    "                train_entities.append((e1, e2))\n",
    "                train_contents.append(content)\n",
    "\n",
    "        elif n_line % 4 == 1:\n",
    "            if empty_content == False:\n",
    "                line = line.strip()\n",
    "                relation_class = match_relation(line)\n",
    "                ys.append(relation_class)\n",
    "\n",
    "                _class[relation_class] = _class.get(relation_class, 0) + 1\n",
    "\n",
    "        elif n_line % 4 == 2:\n",
    "            if empty_content == False:\n",
    "                comment = line.strip()\n",
    "                comments.append(comment)\n",
    "\n",
    "        else:  # ignore Comment\n",
    "            pass\n",
    "\n",
    "#         print (line)\n",
    "#         input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = \"./data/TEST_FILE.txt\"\n",
    "    \n",
    "test_entities = []\n",
    "test_contents = []\n",
    "\n",
    "\n",
    "with open(TEST_PATH, 'r') as f:\n",
    "    n = 0\n",
    "    for n_line, line in enumerate(f.readlines()):\n",
    "\n",
    "        e1, e2, content = clean_text(line)\n",
    "       \n",
    "        if empty_content == False:\n",
    "            test_entities.append((e1, e2))\n",
    "            test_contents.append(content)\n",
    "\n",
    "#         print (line)\n",
    "#         input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [content.split(' ') for content in train_contents+test_contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build ELMO embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 259,  100,  112,  ...,  261,  261,  261],\n",
      "         [ 259,  112,  103,  ...,  261,  261,  261],\n",
      "         [ 259,   98,  111,  ...,  261,  261,  261],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[ 259,  100,  105,  ...,  261,  261,  261],\n",
      "         [ 259,  120,   98,  ...,  261,  261,  261],\n",
      "         [ 259,  100,   98,  ...,  261,  261,  261],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[ 259,   98,  118,  ...,  261,  261,  261],\n",
      "         [ 259,  112,  103,  ...,  261,  261,  261],\n",
      "         [ 259,   98,  260,  ...,  261,  261,  261],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 259,  118,  110,  ...,  261,  261,  261],\n",
      "         [ 259,  103,  115,  ...,  261,  261,  261],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[ 259,  103,  106,  ...,  261,  261,  261],\n",
      "         [ 259,  110,   98,  ...,  261,  261,  261],\n",
      "         [ 259,   99,  122,  ...,  261,  261,  261],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[ 259,  100,   98,  ...,  261,  261,  261],\n",
      "         [ 259,  105,  106,  ...,  261,  261,  261],\n",
      "         [ 259,  120,  102,  ...,  261,  261,  261],\n",
      "         ...,\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0],\n",
      "         [   0,    0,    0,  ...,    0,    0,    0]]])\n",
      "(10717, 32, 1024)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./allennlp')\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from allennlp.common.file_utils import cached_path\n",
    "import spacy\n",
    "import h5py\n",
    "spacy.load(\"en\")\n",
    "\n",
    "\n",
    "options_file = \"./pretrained_word2vec/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "weight_file = './pretrained_word2vec/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
    "\n",
    "elmo = Elmo(options_file, weight_file, 2, dropout=0)\n",
    "\n",
    "# use batch_to_ids to convert sentences to character ids\n",
    "# sentences = [['cat', 'dogdsfeefws', '.']]\n",
    "# sentences = [['cat', 'dogdsfeefws', '.'] for i in range(8000)]\n",
    "\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids)\n",
    "print (character_ids)\n",
    "print (embeddings[\"elmo_representations\"][0].data.numpy().shape)\n",
    "# print ('-'*30)\n",
    "# print (embeddings[\"elmo_representations\"][1])\n",
    "# print (embeddings[\"elmo_representations\"][0].shape)\n",
    "# print (embeddings[\"elmo_representations\"][1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create file: ./data/elmo_x_test.npy\n"
     ]
    }
   ],
   "source": [
    "np.save('./data/elmo_x_test.npy', embeddings[\"elmo_representations\"][0].data.numpy()[8000:])\n",
    "print (\"create file: ./data/elmo_x_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create file: ./data/elmo_x_train.npy\n"
     ]
    }
   ],
   "source": [
    "np.save('./data/elmo_x_train.npy', embeddings[\"elmo_representations\"][0].data.numpy()[:8000])\n",
    "print (\"create file: ./data/elmo_x_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2717, 32, 1024)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"elmo_representations\"][0].data.numpy()[8000:].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
